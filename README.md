# ๐ง Manual Neural Network (Python + NumPy)

### ๐ฌ๐ง English | ๐ธ๐พ ุงูุนุฑุจูุฉ (ุจุงูุฃุณูู)

## Overview
This project implements a basic **Neural Network from scratch** using only `NumPy`.  
It demonstrates how forward propagation, backpropagation, and gradient descent work internally โ without relying on machine learning libraries like TensorFlow or PyTorch.

## Features
- Manual forward and backward pass
- Sigmoid activation
- Mean Squared Error loss
- Two-layer architecture (input โ hidden โ output)
- Clean, simple, and modifiable structure

## How to Run
```bash
python manual_NN.py
```
Requirements
Python 3.x
matplotlip
NumPy

ูุคูู : OsamaAt
__________________________________________________________________________________________________________________________________________________________________________________________________________________
๐ง ุงูุดุจูุฉ ุงูุนุตุจูุฉ ุงููุฏููุฉ (ุจุงุณุชุฎุฏุงู Python ูNumPy)
ูุธุฑุฉ ุนุงูุฉ
ูุฐุง ุงููุดุฑูุน ููุฏูู ูููุฐุฌ ุดุจูุฉ ุนุตุจูุฉ ูุจูู ูุฏูููุง ุจุงููุงูู ุจุฏูู ุงุณุชุฎุฏุงู ุฃู ููุชุจุฉ ุชุนูู ุนููู ูุซู Keras ุฃู PyTorch.
ุงููุฏู ูู ููู ุงูุนูููุงุช ุงูุฏุงุฎููุฉ ููุดุจูุฉ ุงูุนุตุจูุฉุ ูุซู ุงูุงูุชุดุงุฑ ุงูุฃูุงูู ูุงูุชุบุฐูุฉ ุงูุฑุงุฌุนุฉ (Backpropagation) ูุงูุชุญุฏูุซ ุจุงุณุชุฎุฏุงู Gradient Descent.

ูููุฒุงุช ุงููุดุฑูุน
ุชูููุฐ ูุฏูู ููู forward ูุงูู backward

ุฏุงูุฉ ุชูุนูู Sigmoid

ุฏุงูุฉ ุฎุทุฃ Mean Squared Error

ุทุจูุชุงู ุจุณูุทุชุงู: (ุฅุฏุฎุงู โ ูุฎูู โ ุฅุฎุฑุงุฌ)

ุงูููุฏ ุจุณูุท ููุงุจู ููุชุนุฏูู ุจุณูููุฉ

ุทุฑููุฉ ุงูุชุดุบูู

```bash
python manual_NN.py
```
ูุซุงู
ุชุฏุฑูุจ ุดุจูุฉ ุจุณูุทุฉ ูุชุนููู ุฃููุงุท ููุทููุฉ (ูุซู AND ุฃู XOR).
ุงููุชุทูุจุงุช
Python 3.x

ููุชุจุฉ NumPy , matplotlip

ูุคูู : OsamaAt
